{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a href=\"https://cognitiveclass.ai\"><img src = \"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/Logos/organization_logo/organization_logo.png\" width = 400> </a>\n",
    "\n",
    "<h1 align=center><font size = 5>Pre-Trained Models</font></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Introduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "In this lab, you will learn how to leverage pre-trained models to build image classifiers instead of building a model from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Table of Contents\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "\n",
    "<font size = 3> \n",
    "    \n",
    "1. <a href=\"#item31\">Import Libraries and Packages</a>\n",
    "2. <a href=\"#item32\">Download Data</a>  \n",
    "3. <a href=\"#item33\">Define Global Constants</a>  \n",
    "4. <a href=\"#item34\">Construct ImageDataGenerator Instances</a>  \n",
    "5. <a href=\"#item35\">Compile and Fit Model</a>\n",
    "\n",
    "</font>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a id='item31'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Import Libraries and Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Let's start the lab by importing the libraries that we will be using in this lab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "First, we will import the ImageDataGenerator module since we will be leveraging it to train our model in batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "In this lab, we will be using the Keras library to build an image classifier, so let's download the Keras library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import os\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Finally, we will be leveraging the ResNet50 model to build our classifier, so let's download it as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from keras.applications import ResNet50\n",
    "from keras.applications.resnet import preprocess_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a id='item32'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Download Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "For your convenience, I have placed the data on a server which you can retrieve easily using the **wget** command. So let's run the following line of code to get the data. Given the large size of the image dataset, it might take some time depending on your internet speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "## get the data\n",
    "!wget https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/concrete_data_week3.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "And now if you check the left directory pane, you should see the zipped file *concrete_data_week3.zip* appear. So, let's go ahead and unzip the file to access the images. Given the large number of images in the dataset, this might take a couple of minutes, so please be patient, and wait until the code finishes running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'unzip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!unzip -q concrete_data_week3.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store', 'negative', 'positive']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('concrete_data_week3/valid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Now, you should see the folder *concrete_data_week3* appear in the left pane. If you open this folder by double-clicking on it, you will find that it contains two folders: *train* and *valid*. And if you explore these folders, you will find that each contains two subfolders: *positive* and *negative*. These are the same folders that we saw in the labs in the previous modules of this course, where *negative* is the negative class and it represents the concrete images with no cracks and *positive* is the positive class and it represents the concrete images with cracks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "**Important Note**: There are thousands and thousands of images in each folder, so please don't attempt to double click on the *negative* and *positive* folders. This may consume all of your memory and you may end up with a **50*** error. So please **DO NOT DO IT**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a id='item33'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Define Global Constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Here, we will define constants that we will be using throughout the rest of the lab. \n",
    "\n",
    "1. We are obviously dealing with two classes, so *num_classes* is 2. \n",
    "2. The ResNet50 model was built and trained using images of size (224 x 224). Therefore, we will have to resize our images from (227 x 227) to (224 x 224).\n",
    "3. We will training and validating the model using batches of 100 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "\n",
    "image_resize = 224\n",
    "\n",
    "batch_size_training = 100\n",
    "batch_size_validation = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a id='item34'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Construct ImageDataGenerator Instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "In order to instantiate an ImageDataGenerator instance, we will set the **preprocessing_function** argument to *preprocess_input* which we imported from **keras.applications.resnet50** in order to preprocess our images the same way the images used to train ResNet50 model were processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "data_generator = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Next, we will use the *flow_from_directory* method to get the training images as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30001 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = data_generator.flow_from_directory(\n",
    "    'concrete_data_week3/train',\n",
    "    target_size=(image_resize, image_resize),\n",
    "    batch_size=batch_size_training,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "**Your Turn**: Use the *flow_from_directory* method to get the validation images and assign the result to **validation_generator**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10001 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "## Type your answer here\n",
    "validation_generator = data_generator.flow_from_directory(\n",
    "    \"concrete_data_week3/valid\",\n",
    "    target_size=(image_resize, image_resize),\n",
    "    batch_size=batch_size_validation,\n",
    "    class_mode=\"categorical\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Double-click __here__ for the solution.\n",
    "<!-- The correct answer is:\n",
    "validation_generator = data_generator.flow_from_directory(\n",
    "    'concrete_data_week3/valid',\n",
    "    target_size=(image_resize, image_resize),\n",
    "    batch_size=batch_size_validation,\n",
    "    class_mode='categorical')\n",
    "-->\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a id='item35'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Build, Compile and Fit Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "In this section, we will start building our model. We will use the Sequential model class from Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Next, we will add the ResNet50 pre-trained model to out model. However, note that we don't want to include the top layer or the output layer of the pre-trained model. We actually want to define our own output layer and train it so that it is optimized for our image dataset. In order to leave out the output layer of the pre-trained model, we will use the argument *include_top* and set it to **False**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "model.add(ResNet50(\n",
    "    include_top=False,\n",
    "    pooling='avg',\n",
    "    weights='imagenet',\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Then, we will define our output layer as a **Dense** layer, that consists of two nodes and uses the **Softmax** function as the activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "You can access the model's layers using the *layers* attribute of our model object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.functional.Functional at 0x15dd38c5d20>,\n",
       " <keras.layers.core.dense.Dense at 0x15dd14cc670>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "You can see that our model is composed of two sets of layers. The first set is the layers pertaining to ResNet50 and the second set is a single layer, which is our Dense layer that we defined above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "You can access the ResNet50 layers by running the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.input_layer.InputLayer at 0x15dd1678610>,\n",
       " <keras.layers.reshaping.zero_padding2d.ZeroPadding2D at 0x15dd14d8220>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x15dd03e3d90>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x15dd14d9270>,\n",
       " <keras.layers.core.activation.Activation at 0x15dd14da110>,\n",
       " <keras.layers.reshaping.zero_padding2d.ZeroPadding2D at 0x15dd14e6aa0>,\n",
       " <keras.layers.pooling.max_pooling2d.MaxPooling2D at 0x15dd14e7d90>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x15dd14e9ea0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x15dd14e8670>,\n",
       " <keras.layers.core.activation.Activation at 0x15dd150ada0>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x15dd150b460>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x15dd1515450>,\n",
       " <keras.layers.core.activation.Activation at 0x15dd1516200>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x15dd14e8520>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x15dd15169b0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x15dd14e9000>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x15dd15178b0>,\n",
       " <keras.layers.merging.add.Add at 0x15dd1546560>,\n",
       " <keras.layers.core.activation.Activation at 0x15dd1515cf0>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x15dd150bb80>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x15dd14e80a0>,\n",
       " <keras.layers.core.activation.Activation at 0x15dd14e78b0>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x15dd1515540>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x15dd14d8700>,\n",
       " <keras.layers.core.activation.Activation at 0x15dd14ea7a0>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x15dd1552bc0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x15dd1553c10>,\n",
       " <keras.layers.merging.add.Add at 0x15dd1553d30>,\n",
       " <keras.layers.core.activation.Activation at 0x15dd1564c40>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x15dd1565a20>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x15dd1566800>,\n",
       " <keras.layers.core.activation.Activation at 0x15dd15647c0>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x15dd15cb6d0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x15dd15cb910>,\n",
       " <keras.layers.core.activation.Activation at 0x15dd15cb2b0>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x15dd15e0550>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x15dd15e3190>,\n",
       " <keras.layers.merging.add.Add at 0x15dd15e3580>,\n",
       " <keras.layers.core.activation.Activation at 0x15dd15e2590>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x15dd15ecfa0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x15dd15eeb30>,\n",
       " <keras.layers.core.activation.Activation at 0x15dd15ef010>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x15dd17591b0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x15dd175bac0>,\n",
       " <keras.layers.core.activation.Activation at 0x15dd175af20>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x15dd15ecf10>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x15dd27a4160>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x15dd15e2800>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x15dd27a5210>,\n",
       " <keras.layers.merging.add.Add at 0x15dd15ecbe0>,\n",
       " <keras.layers.core.activation.Activation at 0x15dd27a41f0>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x15dd27a7640>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x15dd27a7b80>,\n",
       " <keras.layers.core.activation.Activation at 0x15dd27a75b0>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x15dd27c0940>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x15dd27a48b0>,\n",
       " <keras.layers.core.activation.Activation at 0x15dd27a49d0>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x15dd15eefb0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x15dd15e0880>,\n",
       " <keras.layers.merging.add.Add at 0x15dd15c81c0>,\n",
       " <keras.layers.core.activation.Activation at 0x15dd1565420>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x15dd14d9390>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x15dd14d9ae0>,\n",
       " <keras.layers.core.activation.Activation at 0x15dd27c0640>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x15dd27c2e30>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x15dd27c28f0>,\n",
       " <keras.layers.core.activation.Activation at 0x15dd27c2a70>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x15dd27cd090>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x15dd27cdf00>,\n",
       " <keras.layers.merging.add.Add at 0x15dd27c1990>,\n",
       " <keras.layers.core.activation.Activation at 0x15dd27ceec0>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x15dd27ce560>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x15dd27ce860>,\n",
       " <keras.layers.core.activation.Activation at 0x15dd27cea70>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x15dd27d53c0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x15dd27d4040>,\n",
       " <keras.layers.core.activation.Activation at 0x15dd27d7460>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x15dd27d7af0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x15dd27d44c0>,\n",
       " <keras.layers.merging.add.Add at 0x15dd27d6ce0>,\n",
       " <keras.layers.core.activation.Activation at 0x15dd27ee080>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x15dd27ef9a0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x15dd27eee60>,\n",
       " <keras.layers.core.activation.Activation at 0x15dd2805e40>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x15dd28064d0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x15dd2807790>,\n",
       " <keras.layers.core.activation.Activation at 0x15dd2806290>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x15dd27ee9b0>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x15dd2806d40>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x15dd27ef790>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x15dd2821c00>,\n",
       " <keras.layers.merging.add.Add at 0x15dd2805150>,\n",
       " <keras.layers.core.activation.Activation at 0x15dd2804c10>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x15dd27ee020>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x15dd27edd50>,\n",
       " <keras.layers.core.activation.Activation at 0x15dd27d57b0>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x15dd27cf7f0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x15dd27c2bf0>,\n",
       " <keras.layers.core.activation.Activation at 0x15dd15655d0>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x15dd2820520>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x15dd28230a0>,\n",
       " <keras.layers.merging.add.Add at 0x15dd2821ea0>,\n",
       " <keras.layers.core.activation.Activation at 0x15dd2835a80>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x15dd28365c0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x15dd28373a0>,\n",
       " <keras.layers.core.activation.Activation at 0x15dd28370a0>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x15dd2838130>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x15dd2839300>,\n",
       " <keras.layers.core.activation.Activation at 0x15dd2838be0>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x15dd28381f0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x15dd283bbb0>,\n",
       " <keras.layers.merging.add.Add at 0x15dd283b8e0>,\n",
       " <keras.layers.core.activation.Activation at 0x15dd3820610>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x15dd3821900>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x15dd283b0d0>,\n",
       " <keras.layers.core.activation.Activation at 0x15dd38218a0>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x15dd3822bc0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x15dd38235e0>,\n",
       " <keras.layers.core.activation.Activation at 0x15dd3821450>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x15dd3834dc0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x15dd3836680>,\n",
       " <keras.layers.merging.add.Add at 0x15dd3836a70>,\n",
       " <keras.layers.core.activation.Activation at 0x15dd38370a0>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x15dd38378b0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x15dd38348b0>,\n",
       " <keras.layers.core.activation.Activation at 0x15dd384d3c0>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x15dd384da50>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x15dd384e9b0>,\n",
       " <keras.layers.core.activation.Activation at 0x15dd384f340>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x15dd384f940>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x15dd384dc00>,\n",
       " <keras.layers.merging.add.Add at 0x15dd384da20>,\n",
       " <keras.layers.core.activation.Activation at 0x15dd283a1d0>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x15dd2839e40>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x15dd3834910>,\n",
       " <keras.layers.core.activation.Activation at 0x15dd15659c0>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x15dd2821ff0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x15dd384ea70>,\n",
       " <keras.layers.core.activation.Activation at 0x15dd2823d30>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x15dd386a7d0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x15dd386b1c0>,\n",
       " <keras.layers.merging.add.Add at 0x15dd28370d0>,\n",
       " <keras.layers.core.activation.Activation at 0x15dd3869e10>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x15dd386af50>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x15dd386bd30>,\n",
       " <keras.layers.core.activation.Activation at 0x15dd3873be0>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x15dd3873d00>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x15dd3873dc0>,\n",
       " <keras.layers.core.activation.Activation at 0x15dd38734c0>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x15dd386a140>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x15dd38735b0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x15dd386b310>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x15dd388a410>,\n",
       " <keras.layers.merging.add.Add at 0x15dd3871180>,\n",
       " <keras.layers.core.activation.Activation at 0x15dd388ba00>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x15dd388bbe0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x15dd388a7a0>,\n",
       " <keras.layers.core.activation.Activation at 0x15dd388b190>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x15dd388a830>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x15dd38b2020>,\n",
       " <keras.layers.core.activation.Activation at 0x15dd38b1d80>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x15dd38b1c90>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x15dd38b3ca0>,\n",
       " <keras.layers.merging.add.Add at 0x15dd38b36a0>,\n",
       " <keras.layers.core.activation.Activation at 0x15dd38b3a00>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x15dd38b2da0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x15dd38c6050>,\n",
       " <keras.layers.core.activation.Activation at 0x15dd38b28f0>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x15dd38b2830>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x15dd38b0d90>,\n",
       " <keras.layers.core.activation.Activation at 0x15dd388ab30>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x15dd38b03d0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x15dd3870070>,\n",
       " <keras.layers.merging.add.Add at 0x15dd15ede10>,\n",
       " <keras.layers.core.activation.Activation at 0x15dd388ab60>,\n",
       " <keras.layers.pooling.global_average_pooling2d.GlobalAveragePooling2D at 0x15dd28204c0>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Since the ResNet50 model has already been trained, then we want to tell our model not to bother with training the ResNet part, but to train only our dense output layer. To do that, we run the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "model.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "And now using the *summary* attribute of the model, we can see how many parameters we will need to optimize in order to train the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50 (Functional)       (None, 2048)              23587712  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 4098      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,591,810\n",
      "Trainable params: 4,098\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Next we compile our model using the **adam** optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Before we are able to start the training process, with an ImageDataGenerator, we will need to define how many steps compose an epoch. Typically, that is the number of images divided by the batch size. Therefore, we define our steps per epoch as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "steps_per_epoch_training = len(train_generator)\n",
    "steps_per_epoch_validation = len(validation_generator)\n",
    "num_epochs = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Finally, we are ready to start training our model. Unlike a conventional deep learning training were data is not streamed from a directory, with an ImageDataGenerator where data is augmented in batches, we use the **fit_generator** method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "fit_history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=steps_per_epoch_training,\n",
    "    epochs=num_epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=steps_per_epoch_validation,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Now that the model is trained, you are ready to start using it to classify images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Since training can take a long time when building deep learning models, it is always a good idea to save your model once the training is complete if you believe you will be using the model again later. You will be using this model in the next module, so go ahead and save your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "model.save('classifier_resnet_model.h5', include_optimizer=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Now, you should see the model file *classifier_resnet_model.h5* apprear in the left directory pane."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Thank you for completing this lab!\n",
    "\n",
    "This notebook was created by Alex Aklson. I hope you found this lab interesting and educational."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "This notebook is part of a course on **Coursera** called *AI Capstone Project with Deep Learning*. If you accessed this notebook outside the course, you can take this course online by clicking [here](https://cocl.us/DL0321EN_Coursera_Week3_LAB1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<hr>\n",
    "\n",
    "Copyright &copy; 2020 [IBM Developer Skills Network](https://cognitiveclass.ai/?utm_source=bducopyrightlink&utm_medium=dswb&utm_campaign=bdu). This notebook and its source code are released under the terms of the [MIT License](https://bigdatauniversity.com/mit-license/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
